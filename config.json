{
    "address": "",
    "description": "The default GaiaNet node config with a Llama2-7b-chat model and a Paris tour guide knowledge base.",
    "chat": "https://huggingface.co/second-state/Llama-2-7B-Chat-GGUF/resolve/main/Llama-2-7b-chat-hf-Q5_K_M.gguf",
    "prompt_template": "llama-2-chat",
    "reverse_prompt": "",
    "chat_ctx_size": "4096",
    "system_prompt": "You are a helpful, respectful and honest assistant. Always answer accurately, while being safe.",
    "embedding": "https://huggingface.co/second-state/All-MiniLM-L6-v2-Embedding-GGUF/resolve/main/all-MiniLM-L6-v2-ggml-model-f16.gguf",
    "embedding_ctx_size": "384",
    "snapshot": "https://huggingface.co/datasets/gaianet/paris/resolve/main/paris_384_all-minilm-l6-v2_f16.snapshot",
    "embedding_collection_name": "default",
    "rag_prompt": "Use the following pieces of context to answer the user's question.\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\n----------------\n",
    "domain": "gaianet.network",
    "llamaedge_port": "8080"
}